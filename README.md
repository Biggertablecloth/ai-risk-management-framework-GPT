
# ai-risk-management-framework-GPT
This is a readme for the NIST AI RMF GPT that we created to help companies navigate AI risk. It is based on the NIST AI RMF playbook. [You can try it out here](https://chat.openai.com/g/g-QuZUJtjV1-ai-risk-navigator).

## Presets
The following are the presets we encourage users to begin with. Of course the custom GPT can accept any input, but these are ideas to get you started. 

 - Tell me about an AI Risk Topic. 
 - Advise me on AI risk management. 
 - How should we prepare for NIST RMF attestation? 
 - Draft an AI policy for my business type. 
 - Develop a risk profile for our AI usage. 
 - Look at my current AI policy (attached) and help me evaluate it. 
 - Show me links to sections of the NIST AI RMF Playbook based on my concerns.

## Goals for this Project
This is a tool that should be useful for organizations of all types. The NIST AI Risk Management Framework is the gold standard for managing AI risk in organizations. As such it's big and intimidating and can be hard to grok in a way that helps organizations big or small get started with meaningful and responsible policies. This should demystify the process and ultimately be used a tool to help guide your internal efforts. 

Whether you are simply trying to put your arms around your own employees who want to experiment with LLMs or whether you are an organizations whose very business centers on the use of AI, this tool should help uncover areas of concern and give you the proper guidance on mitigating them. 

## How can you help?
Please share your conversations with us. Email kelly@tablecloth.io a link to your session. If you can tell me where it did a good job and where it failed, that would also help. Understanding a broad base of use cases will help me continue to train it to be more intelligent. 

## More information on AI Risk Management

 - [The NIST AI RMF](https://www.nist.gov/itl/ai-risk-management-framework) and the [The NIST AI RMF Playbook](https://airc.nist.gov/AI_RMF_Knowledge_Base/Playbook)  itself. 
  
 - [EU - Assessment List for Trustworthy Artificial Intelligence
   (ALTAI) for self-assessment](https://digital-strategy.ec.europa.eu/en/library/assessment-list-trustworthy-artificial-intelligence-altai-self-assessment) with  [guidelines](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai) and [assessment list](https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=68342) (PDF) and [web based version](https://futurium.ec.europa.eu/en/european-ai-alliance/pages/welcome-altai-portal) (login required).

- [Whitehouse: Blueprint for an AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)  and  the [Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)

- OECD -   [Public Policy Guidelines](https://www.oecd-ilibrary.org/sites/eedfee77-en/1/2/4/index.html?itemId=/content/publication/eedfee77-en&_csp_=5c39a73676a331d76fa56f36ff0d4aca&itemIGO=oecd&itemContentType=book) and [AI Policies and initiatives](https://www.oecd-ilibrary.org/sites/eedfee77-en/1/2/5/index.html?itemId=/content/publication/eedfee77-en&_csp_=5c39a73676a331d76fa56f36ff0d4aca&itemIGO=oecd&itemContentType=book)

- US Office of Management and Budget - [Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence](https://www.whitehouse.gov/wp-content/uploads/2023/11/AI-in-Government-Memo-draft-for-public-review.pdf) (PDF)

- IEEE's Ethically Aligned Design. Information about this can be found on the [IEEE Standards Association website](https://standards.ieee.org/), but I wasn't able to retrieve a direct link to the document.

- Singapore. [Monetary Authority of Singapore - AI Governance Framework](https://www.mas.gov.sg/)

- UK's AI Code of Ethics: [UK Government - AI Ethics and Safety](https://www.gov.uk/guidance/understanding-artificial-intelligence-ethics-and-safety)
- AI Now Institute's Framework: [AI Now Institute](https://ainowinstitute.org/)

- Partnership on AI's Tenets: [Partnership on AI](https://partnershiponai.org/)

- World Economic Forum's AI Ethics Framework: Details can be found on the [World Economic Forum website](https://www.weforum.org/), though a direct link to the framework was not retrieved.

## Examples of AI Gone Wrong
- https://incidentdatabase.ai/
- https://www.aiaaic.org/
- https://www.aiethicist.org/

## Changelog
As I make changes, they will be listed here.

### February 15, 2024
1. Please add the following text to the end of every response: "This is a work in progress and it is open source. To learn more or contribute, go here: https://github.com/Biggertablecloth/ai-risk-management-framework-GPT"

### February 2, 2024
1.  Enhanced Knowledge Base: Your expertise now includes a comprehensive understanding of the NIST playbook, along with over 500 related publications. This expanded knowledge base enables you to offer even more detailed and informed advice on AI Risk Management.
2.  Customizable Risk Assessment Templates: You have been upgraded with the ability to generate customizable risk assessment templates. These templates are tailored to the user’s specific industry, technology stack, and regulatory requirements, providing a personalized starting point for AI risk assessments.
3.  Real-time Updates on AI Regulations and Standards: You now possess real-time update capabilities on relevant AI regulations and standards. This ensures that CTOs and other stakeholders have access to the most current information for compliance purposes.
4.  Library of Anonymized Case Studies: A library of anonymized case studies demonstrating successful AI risk management strategies across different industries has been incorporated into your functionality. This offers practical insights and benchmarks for users.
5.  Interactive Workshops or Webinars: Your role now includes the capability to facilitate interactive workshops or webinars. This function allows for direct engagement with experts and peers on complex AI risk management issues in a collaborative learning environment.
6.  Collaborative Tool Functionality: You are designed to function as a collaborative tool where CTOs can work with their teams, assigning tasks, sharing insights, and tracking progress on their risk management activities. This promotes effective communication and collaboration among team members.
7.  Personalized Recommendations Based on User’s Risk Profile: Your abilities have been refined to provide personalized recommendations. Leveraging data analytics, you can predict potential vulnerabilities and suggest mitigation strategies based on the user’s specific risk profile.

### January 23, 2024
1. Created
